#!/usr/bin/env python
"""
Compare w_factor study simulations against their base simulations.

For each base simulation (gabs_fine_060, 078, etc.), creates a plot showing:
- The base simulation error norms
- The 6 dd_exp_w_factor_study variants derived from that base (w_factors: 1e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1)

This helps visualize the impact of different w_factor values on data assimilation performance.

Usage:
    python compare_w_factor_vs_base.py <exp_csv> [--wdir ./data] [--plot-dir plots/w_factor_comparison]
    python compare_w_factor_vs_base.py --from-results [--error-dir plots/error_plots] [--plot-dir plots/w_factor_comparison]
"""
from __future__ import print_function, division, absolute_import

import sys
import os
import argparse
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# Import the error calculation functions
from calculate_slip_error_norms import (
    load_experimental_data, load_simulation_data, compute_error_norms
)

# Configuration from dd_experimental_data_runs.py
BASE_SIMS = [
    "gabs_fine_060", "gabs_fine_078", "gabs_fine_096", "gabs_fine_112",
    "gabs_fine_118", "gabs_fine_124", "gabs_fine_136", "gabs_fine_142",
    "gabs_fine_154", "gabs_fine_160"
]

W_FACTORS = [1.0e-4, 1.0e-3, 5.0e-3, 1.0e-2, 5.0e-2, 1.0e-1]

def get_dd_sim_name(base_index, w_factor_index):
    """
    Get the dd_exp_w_factor_study simulation name for a given base and w_factor.
    
    The simulations are generated by cycling through bases for each w_factor:
    - sim 001-010: w_factor=1e-4, bases 060, 078, ..., 160
    - sim 011-020: w_factor=1e-3, bases 060, 078, ..., 160
    - etc.
    """
    sim_id = w_factor_index * len(BASE_SIMS) + base_index + 1
    return "dd_exp_w_factor_study_{:03d}".format(sim_id)


def parse_dd_sim_id(sim_name):
    """Return (base_index, w_factor_index) from dd_exp_w_factor_study_XXX."""
    try:
        sim_id = int(sim_name.split('_')[-1])
    except Exception:
        return None, None
    base_index = (sim_id - 1) % len(BASE_SIMS)
    w_factor_index = (sim_id - 1) // len(BASE_SIMS)
    if w_factor_index < 0 or w_factor_index >= len(W_FACTORS):
        return None, None
    return base_index, w_factor_index


def load_results_from_csv(error_dir):
    """Load precomputed error results and group by base simulation."""
    dd_file = os.path.join(error_dir, 'dd_study_ALL_error_results.csv')
    gabs_file = os.path.join(error_dir, 'gabs_fine_error_results.csv')

    if not os.path.exists(dd_file):
        raise RuntimeError('Missing dd results file: {}'.format(dd_file))
    if not os.path.exists(gabs_file):
        raise RuntimeError('Missing gabs results file: {}'.format(gabs_file))

    dd_df = pd.read_csv(dd_file)
    gabs_df = pd.read_csv(gabs_file)

    results = {base_sim: {'base': None, 'w_factors': []} for base_sim in BASE_SIMS}

    # Base simulations from gabs_fine_error_results.csv
    for _, row in gabs_df.iterrows():
        sim_name = row['simulation']
        if sim_name in results:
            results[sim_name]['base'] = {
                'sim_name': sim_name,
                'l2_norm': row['l2_norm'],
                'linf_norm': row['linf_norm']
            }

    # dd_exp_w_factor_study results from dd_study_ALL_error_results.csv
    for _, row in dd_df.iterrows():
        sim_name = row['simulation']
        base_index, w_factor_index = parse_dd_sim_id(sim_name)
        if base_index is None:
            continue
        base_sim = BASE_SIMS[base_index]
        w_factor = W_FACTORS[w_factor_index]
        results[base_sim]['w_factors'].append({
            'sim_name': sim_name,
            'w_factor': w_factor,
            'l2_norm': row['l2_norm'],
            'linf_norm': row['linf_norm']
        })

    # Sort w_factor entries for consistency
    for base_sim in results:
        results[base_sim]['w_factors'] = sorted(
            results[base_sim]['w_factors'], key=lambda r: r['w_factor']
        )

    return results


def compute_all_errors(exp_t, exp_data, exp_positions, args):
    """
    Compute error norms for all base simulations and their w_factor variants.
    
    Returns:
        dict: {base_sim_name: {
            'base': error_results,
            'w_factors': [error_results for each w_factor]
        }}
    """
    results = {}
    
    for base_idx, base_sim in enumerate(BASE_SIMS):
        print("\n" + "="*70)
        print("Processing BASE: {} (index {})".format(base_sim, base_idx))
        print("="*70)
        
        base_results = {}
        
        # 1. Compute error for base simulation
        print("\n--- Base Simulation ---")
        try:
            sim_t, sim_data, sim_pos = load_simulation_data(
                base_sim, args.group, sensor_x=exp_positions, wdir=args.wdir
            )
            base_error = compute_error_norms(
                sim_t, sim_data, exp_t, exp_data,
                t_min=args.t_min, t_max=args.t_max,
                use_exp_times=not args.dense_grid
            )
            base_error['sim_name'] = base_sim
            base_results['base'] = base_error
            print("  L2: {:.4f} microns, L-inf: {:.4f} microns".format(
                base_error['l2_norm'], base_error['linf_norm']))
        except Exception as e:
            print("  ERROR loading {}: {}".format(base_sim, e))
            continue
        
        # 2. Compute errors for all w_factor variants
        print("\n--- w_factor Variants ---")
        w_factor_results = []
        for w_idx, w_val in enumerate(W_FACTORS):
            dd_sim = get_dd_sim_name(base_idx, w_idx)
            print("  w_factor={:.0e} -> {}".format(w_val, dd_sim))
            
            try:
                sim_t, sim_data, sim_pos = load_simulation_data(
                    dd_sim, args.group, sensor_x=exp_positions, wdir=args.wdir
                )
                dd_error = compute_error_norms(
                    sim_t, sim_data, exp_t, exp_data,
                    t_min=args.t_min, t_max=args.t_max,
                    use_exp_times=not args.dense_grid
                )
                dd_error['sim_name'] = dd_sim
                dd_error['w_factor'] = w_val
                w_factor_results.append(dd_error)
                print("    L2: {:.4f} microns, L-inf: {:.4f} microns".format(
                    dd_error['l2_norm'], dd_error['linf_norm']))
            except Exception as e:
                print("    ERROR loading {}: {}".format(dd_sim, e))
                continue
        
        base_results['w_factors'] = w_factor_results
        results[base_sim] = base_results
    
    return results


def plot_w_factor_comparison(base_sim, base_error, w_factor_errors, output_dir):
    """
    Create a comparison plot for one base simulation and its w_factor variants.
    
    Args:
        base_sim: name of base simulation
        base_error: error results dict for base
        w_factor_errors: list of error results dicts for w_factor variants
        output_dir: directory to save plot
    """
    if not w_factor_errors:
        print("  No w_factor results to plot for {}".format(base_sim))
        return
    
    # Extract data
    w_factors = [r['w_factor'] for r in w_factor_errors]
    l2_dd = [r['l2_norm'] for r in w_factor_errors]
    linf_dd = [r['linf_norm'] for r in w_factor_errors]
    
    base_l2 = base_error['l2_norm']
    base_linf = base_error['linf_norm']
    
    # Create figure with 2 subplots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    # --- L2 Norm Plot ---
    ax1.axhline(y=base_l2, color='black', linestyle='--', linewidth=2, 
                label='Base: {:.2f} microns'.format(base_l2), zorder=1)
    ax1.plot(w_factors, l2_dd, 'o-', color='blue', linewidth=2, markersize=8, 
             label='Data-Driven', zorder=2)
    
    ax1.set_xscale('log')
    ax1.set_xlabel('w_factor', fontsize=12, fontweight='bold')
    ax1.set_ylabel('L2 Norm (RMS Error) [microns]', fontsize=12)
    ax1.set_title('L2 Norm: Data-Driven vs Base', fontsize=13, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.legend(fontsize=10)
    
    # Mark best w_factor
    best_l2_idx = np.argmin(l2_dd)
    best_l2_val = l2_dd[best_l2_idx]
    best_l2_w = w_factors[best_l2_idx]
    ax1.plot(best_l2_w, best_l2_val, '*', color='red', markersize=15, 
             label='Best: w={:.0e}'.format(best_l2_w), zorder=3)
    
    # Add improvement percentage
    improvement_l2 = ((base_l2 - best_l2_val) / base_l2) * 100
    ax1.text(0.02, 0.98, 'Best improvement: {:.1f}%'.format(improvement_l2),
             transform=ax1.transAxes, fontsize=10, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='lightgreen' if improvement_l2 > 0 else 'lightyellow', alpha=0.7))
    
    # --- L-infinity Norm Plot ---
    ax2.axhline(y=base_linf, color='black', linestyle='--', linewidth=2,
                label='Base: {:.2f} microns'.format(base_linf), zorder=1)
    ax2.plot(w_factors, linf_dd, 's-', color='red', linewidth=2, markersize=8,
             label='Data-Driven', zorder=2)
    
    ax2.set_xscale('log')
    ax2.set_xlabel('w_factor', fontsize=12, fontweight='bold')
    ax2.set_ylabel('L-inf Norm (Max Error) [microns]', fontsize=12)
    ax2.set_title('L-infinity Norm: Data-Driven vs Base', fontsize=13, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.legend(fontsize=10)
    
    # Mark best w_factor
    best_linf_idx = np.argmin(linf_dd)
    best_linf_val = linf_dd[best_linf_idx]
    best_linf_w = w_factors[best_linf_idx]
    ax2.plot(best_linf_w, best_linf_val, '*', color='blue', markersize=15,
             label='Best: w={:.0e}'.format(best_linf_w), zorder=3)
    
    # Add improvement percentage
    improvement_linf = ((base_linf - best_linf_val) / base_linf) * 100
    ax2.text(0.02, 0.98, 'Best improvement: {:.1f}%'.format(improvement_linf),
             transform=ax2.transAxes, fontsize=10, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='lightgreen' if improvement_linf > 0 else 'lightyellow', alpha=0.7))
    
    # Overall title
    fig.suptitle('w_factor Impact on {}'.format(base_sim), 
                 fontsize=15, fontweight='bold', y=1.00)
    
    plt.tight_layout()
    
    # Save plot
    plot_filename = 'w_factor_comparison_{}.png'.format(base_sim)
    plot_path = os.path.join(output_dir, plot_filename)
    fig.savefig(plot_path, dpi=300, bbox_inches='tight')
    print("  Plot saved: {}".format(plot_path))
    plt.close(fig)


def save_summary_csv(results, output_dir):
    """
    Save a summary CSV with all error results.
    
    CSV format:
        base_sim, w_factor, simulation, l2_norm, linf_norm
    """
    rows = []
    
    for base_sim, data in results.items():
        # Add base simulation
        if 'base' in data:
            rows.append({
                'base_sim': base_sim,
                'w_factor': 0.0,  # Base has no w_factor
                'simulation': base_sim,
                'l2_norm': data['base']['l2_norm'],
                'linf_norm': data['base']['linf_norm']
            })
        
        # Add w_factor variants
        for w_result in data.get('w_factors', []):
            rows.append({
                'base_sim': base_sim,
                'w_factor': w_result['w_factor'],
                'simulation': w_result['sim_name'],
                'l2_norm': w_result['l2_norm'],
                'linf_norm': w_result['linf_norm']
            })
    
    df = pd.DataFrame(rows)
    csv_path = os.path.join(output_dir, 'w_factor_comparison_summary.csv')
    df.to_csv(csv_path, index=False)
    print("\nSummary CSV saved: {}".format(csv_path))
    
    return df


def main():
    parser = argparse.ArgumentParser(
        description='Compare w_factor study simulations against their base simulations'
    )
    parser.add_argument('exp_csv', nargs='?', help='Path to experimental CSV file')
    parser.add_argument('--group', default='interface', help='Field collection group (default: interface)')
    parser.add_argument('--wdir', default='./data', help='Simulation data directory (default: ./data)')
    parser.add_argument('--t-min', type=float, help='Start time for comparison window')
    parser.add_argument('--t-max', type=float, help='End time for comparison window')
    parser.add_argument('--dense-grid', action='store_true',
                        help='Use dense interpolated grid instead of experimental time points only')
    parser.add_argument('--plot-dir', default='plots/w_factor_comparison',
                        help='Directory for output plots (default: plots/w_factor_comparison)')
    parser.add_argument('--from-results', action='store_true',
                        help='Use precomputed error results from plots/error_plots')
    parser.add_argument('--error-dir', default='plots/error_plots',
                        help='Directory containing dd_study_ALL_error_results.csv and gabs_fine_error_results.csv')
    
    args = parser.parse_args()
    
    # Create output directory
    if not os.path.exists(args.plot_dir):
        os.makedirs(args.plot_dir)

    if args.from_results:
        print("\n" + "="*70)
        print("Loading Precomputed Error Results")
        print("="*70)
        results = load_results_from_csv(args.error_dir)
    else:
        if not args.exp_csv:
            raise SystemExit('exp_csv is required unless --from-results is set')
        # Load experimental data
        print("\n" + "="*70)
        print("Loading Experimental Data")
        print("="*70)
        exp_t, exp_data, exp_positions = load_experimental_data(args.exp_csv)

        # Compute all errors
        print("\n" + "="*70)
        print("Computing Error Norms")
        print("="*70)
        results = compute_all_errors(exp_t, exp_data, exp_positions, args)
    
    # Generate plots
    print("\n" + "="*70)
    print("Generating Comparison Plots")
    print("="*70)
    for base_sim, data in results.items():
        if 'base' in data and 'w_factors' in data:
            print("\nPlotting {}...".format(base_sim))
            plot_w_factor_comparison(
                base_sim, data['base'], data['w_factors'], args.plot_dir
            )
    
    # Save summary CSV
    print("\n" + "="*70)
    print("Saving Summary")
    print("="*70)
    df = save_summary_csv(results, args.plot_dir)
    
    # Print best performers
    print("\n" + "="*70)
    print("BEST PERFORMERS BY BASE SIMULATION")
    print("="*70)
    
    for base_sim in BASE_SIMS:
        if base_sim not in results or 'w_factors' not in results[base_sim]:
            continue
        
        base_data = results[base_sim]
        base_l2 = base_data['base']['l2_norm']
        
        w_factor_data = base_data['w_factors']
        if not w_factor_data:
            continue
        
        best_idx = np.argmin([r['l2_norm'] for r in w_factor_data])
        best = w_factor_data[best_idx]
        
        improvement = ((base_l2 - best['l2_norm']) / base_l2) * 100
        
        print("\n{}:".format(base_sim))
        print("  Base L2:         {:.4f} microns".format(base_l2))
        print("  Best w_factor:   {:.0e}".format(best['w_factor']))
        print("  Best L2:         {:.4f} microns".format(best['l2_norm']))
        print("  Improvement:     {:.1f}%".format(improvement))
    
    print("\n" + "="*70)
    print("COMPLETE")
    print("="*70)


if __name__ == "__main__":
    main()
